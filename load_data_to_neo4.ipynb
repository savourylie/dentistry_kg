{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "import pickle\n",
    "from neo4j import GraphDatabase\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from neo4j_helpers import NodeModel, RelationshipModel, create_nodes, create_relationships\n",
    "from data_processing_helpers import flatten_dict\n",
    "\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))\n",
    "\n",
    "train_data_path = 'data/train_data.json'\n",
    "val_data_path = 'data/val_data.json'\n",
    "\n",
    "file_path = 'data/val_result.pkl'\n",
    "\n",
    "with open(train_data_path, 'r') as file:\n",
    "    train_data = [json.loads(line) for line in file.readlines()]\n",
    "\n",
    "with open(val_data_path, 'r') as file:\n",
    "    val_data = [json.loads(line) for line in file.readlines()]\n",
    "                         \n",
    "# Open the file in read-binary mode and load the list of dictionaries\n",
    "with open(file_path, 'rb') as file:\n",
    "    val_result_list = pickle.load(file)\n",
    "\n",
    "train_list = [flatten_dict(item) for item in train_data]\n",
    "val_list = [flatten_dict(item) for item in val_data]\n",
    "\n",
    "train_df = pd.DataFrame(train_list)\n",
    "val_df = pd.DataFrame(val_list)\n",
    "\n",
    "result_list, label_list = zip(*val_result_list)\n",
    "result_df, label_df = pd.DataFrame(result_list), pd.DataFrame(label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14339, 6), (3585, 6))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>object</th>\n",
       "      <th>object_type</th>\n",
       "      <th>predicate</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>产后抑郁症@区分产后抑郁症与轻度情绪失调（产后忧郁或“婴儿忧郁”）是重要的，因为轻度情绪失调...</td>\n",
       "      <td>轻度情绪失调</td>\n",
       "      <td>疾病</td>\n",
       "      <td>鉴别诊断</td>\n",
       "      <td>产后抑郁症</td>\n",
       "      <td>疾病</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>类风湿关节炎@尺侧偏斜是由于MCP关节炎症造成的。</td>\n",
       "      <td>尺侧偏斜</td>\n",
       "      <td>症状</td>\n",
       "      <td>临床表现</td>\n",
       "      <td>MCP关节炎症</td>\n",
       "      <td>疾病</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>唇腭裂@ ### 腭瘘 | 存在差异 | 低 大约 10% 至 20% 颚成形术发生腭瘘。 ...</td>\n",
       "      <td>婴儿伤口</td>\n",
       "      <td>社会学</td>\n",
       "      <td>风险评估因素</td>\n",
       "      <td>腭瘘</td>\n",
       "      <td>疾病</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>成人哮喘@ 应在低剂量 ICS 的基础上加用一种 LABA， 或将ICS增加到中等剂量。 成...</td>\n",
       "      <td>ICS</td>\n",
       "      <td>药物</td>\n",
       "      <td>药物治疗</td>\n",
       "      <td>成人哮喘</td>\n",
       "      <td>疾病</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>口咽癌@[ 声嘶及发声障碍的评估 ](/topics/zh-cn/845) ### 手术或放...</td>\n",
       "      <td>放疗后吞咽困难</td>\n",
       "      <td>疾病</td>\n",
       "      <td>并发症</td>\n",
       "      <td>口咽癌</td>\n",
       "      <td>疾病</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   object object_type  \\\n",
       "0  产后抑郁症@区分产后抑郁症与轻度情绪失调（产后忧郁或“婴儿忧郁”）是重要的，因为轻度情绪失调...   轻度情绪失调          疾病   \n",
       "1                          类风湿关节炎@尺侧偏斜是由于MCP关节炎症造成的。     尺侧偏斜          症状   \n",
       "2  唇腭裂@ ### 腭瘘 | 存在差异 | 低 大约 10% 至 20% 颚成形术发生腭瘘。 ...     婴儿伤口         社会学   \n",
       "3  成人哮喘@ 应在低剂量 ICS 的基础上加用一种 LABA， 或将ICS增加到中等剂量。 成...      ICS          药物   \n",
       "4  口咽癌@[ 声嘶及发声障碍的评估 ](/topics/zh-cn/845) ### 手术或放...  放疗后吞咽困难          疾病   \n",
       "\n",
       "  predicate  subject subject_type  \n",
       "0      鉴别诊断    产后抑郁症           疾病  \n",
       "1      临床表现  MCP关节炎症           疾病  \n",
       "2    风险评估因素       腭瘘           疾病  \n",
       "3      药物治疗     成人哮喘           疾病  \n",
       "4       并发症      口咽癌           疾病  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-large-en\")\n",
    "model = AutoModel.from_pretrained(\"BAAI/bge-large-en\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from typing import List\n",
    "def sentences2embeddings(sentence: str, model, tokenizer) -> pd.Series:\n",
    "    sentence_list = [sentence]\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentence_list, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        # Perform pooling. In this case, cls pooling.\n",
    "        sentence_embeddings = model_output[0][:, 0]\n",
    "    # normalize embeddings\n",
    "    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    embeddings = sentence_embeddings.numpy()[0].tolist()\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "embedding_func = partial(sentences2embeddings, model=model, tokenizer=tokenizer)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_func('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_mask = label_df.map(lambda x: isinstance(x, str)).all(axis=1)\n",
    "# label_df_filtered = label_df[label_mask]\n",
    "\n",
    "# result_mask = result_df.map(lambda x: isinstance(x, str)).all(axis=1)\n",
    "# result_df_filtered = result_df[result_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df.shape, result_df_filtered.shape, label_df.shape, label_df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to wrap numbers with backticks\n",
    "def wrap_numbers_with_backticks(text):\n",
    "    return re.sub(r'(\\d+)', r'`\\1`', text)\n",
    "\n",
    "\n",
    "# Define a regular expression pattern for special characters\n",
    "pattern = r'[^\\u4e00-\\u9fffA-Za-z\\s]'\n",
    "\n",
    "for col in ['subject', 'object', 'predicate']:\n",
    "    # Apply the function to the column\n",
    "    train_df[col] = train_df[col].str.replace(pattern, '', regex=True)\n",
    "    train_df = train_df.drop(train_df[train_df[col] == ''].index)\n",
    "    train_df[col] = train_df[col].str.replace(' ', '_')\n",
    "    \n",
    "    # Remove special characters from 'Column1'\n",
    "    # label_df_filtered[col] = label_df_filtered[col].str.replace(pattern, '', regex=True)\n",
    "    # label_df_filtered = label_df_filtered.drop(label_df_filtered[label_df_filtered[col] == ''].index)\n",
    "    # label_df_filtered[col] = label_df_filtered[col].str.replace(' ', '_')\n",
    "    \n",
    "    # # Apply the function to the column\n",
    "    # result_df_filtered[col] = result_df_filtered[col].str.replace(pattern, '', regex=True)\n",
    "    # result_df_filtered = result_df_filtered.drop(result_df_filtered[result_df_filtered[col] == ''].index)\n",
    "    # result_df_filtered[col] = result_df_filtered[col].str.replace(' ', '_')\n",
    "\n",
    "    # Apply the function to the column\n",
    "    # result_df_filtered[col] = result_df_filtered[col].apply(wrap_numbers_with_backticks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_knowledge_train = NodeModel(\n",
    "    label=(\"hard_coded_label\", \"Knowledge\"),\n",
    "    id_prop=('text', 'text'),\n",
    "    properties={\n",
    "        \"text\": (\"text_embedding\", embedding_func)\n",
    "    }\n",
    ")\n",
    "\n",
    "node_subject_train = NodeModel(\n",
    "    # label=(\"column_name_label\", \"subject\"),\n",
    "    label=(\"hard_coded_label\", \"Subject\"),\n",
    "    id_prop=('subject', 'name'),\n",
    "    properties={\n",
    "        \"subject_type\": (\"type\", None)\n",
    "    },\n",
    "    # extra_labels=['Subject', 'Result']\n",
    ")\n",
    "\n",
    "node_object_train = NodeModel(\n",
    "    # label=(\"column_name_label\", \"object\"),\n",
    "    label=(\"hard_coded_label\", \"Object\"),\n",
    "    id_prop=('object', 'name'),\n",
    "    properties={\n",
    "        \"object_type\": (\"type\", None)\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# node_subject_label = NodeModel(\n",
    "#     label=(\"column_name_label\", \"subject\"),\n",
    "#     id_prop=('subject', 'name'),\n",
    "#     properties={\n",
    "#         \"subject_type\": \"type\"\n",
    "#     },\n",
    "#     extra_labels=['Subject', 'Label']\n",
    "# )\n",
    "\n",
    "# node_object_label = NodeModel(\n",
    "#     label=(\"column_name_label\", \"object\"),\n",
    "#     id_prop=('object', 'name'),\n",
    "#     properties={\n",
    "#         \"object_type\": \"type\"\n",
    "#     },\n",
    "#     extra_labels=['Object', 'Label']\n",
    "# )\n",
    "\n",
    "# node_subject_result = NodeModel(\n",
    "#     # label=(\"column_name_label\", \"subject\"),\n",
    "#     label=(\"hard_coded_label\", \"Subject\"),\n",
    "#     id_prop=('subject', 'name'),\n",
    "#     properties={\n",
    "#         \"subject_type\": \"type\"\n",
    "#     },\n",
    "#     # extra_labels=['Subject', 'Result']\n",
    "# )\n",
    "\n",
    "# node_object_result = NodeModel(\n",
    "#     # label=(\"column_name_label\", \"object\"),\n",
    "#     label=(\"hard_coded_label\", \"Object\"),\n",
    "#     id_prop=('object', 'name'),\n",
    "#     properties={\n",
    "#         \"object_type\": \"type\"\n",
    "#     },\n",
    "#     # extra_labels=['Object', 'Result']\n",
    "# )\n",
    "\n",
    "train_df_copy = train_df.loc[:1000, :].copy()\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.write_transaction(create_nodes, train_df_copy, [node_knowledge_train, node_subject_train, node_object_train])\n",
    "\n",
    "    # session.write_transaction(create_nodes, label_df_filtered, [node_subject_label, node_object_label])\n",
    "    # session.write_transaction(create_nodes, result_df_filtered, [node_subject_result, node_object_result])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l3/n5f9q7991q7_k4kbqdzy70w00000gn/T/ipykernel_85499/1003905425.py:45: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(create_relationships, train_df_copy, [rel_train_knowledge2subject, rel_train_subject2object])\n"
     ]
    }
   ],
   "source": [
    "train_df_copy = train_df.loc[:1000, :].copy()\n",
    "\n",
    "rel_train_knowledge2subject = RelationshipModel(\n",
    "    source_node='Knowledge',\n",
    "    target_node='Subject',\n",
    "    # rel_label=('column_name_label', 'predicate'),\n",
    "    rel_label=('hard_coded_label', 'HAS_SUBJECT'),\n",
    "    source_id=('text', 'text'),\n",
    "    target_id=('subject', 'name'),\n",
    "    # extra_labels=['Predicate', 'Result']\n",
    ")\n",
    "\n",
    "rel_train_subject2object = RelationshipModel(\n",
    "    source_node='Subject',\n",
    "    target_node='Object',\n",
    "    # rel_label=('column_name_label', 'predicate'),\n",
    "    rel_label=('hard_coded_label', 'PREDICATE'),\n",
    "    source_id=('subject', 'name'),\n",
    "    target_id=('object', 'name'),\n",
    "    properties={\n",
    "        \"predicate\": \"type\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# rel_label = RelationshipModel(\n",
    "#     source_node='Subject',\n",
    "#     target_node='Object',\n",
    "#     rel_label=('column_name_label', 'predicate'),\n",
    "#     source_id=('subject', 'name'),\n",
    "#     target_id=('object', 'name'),\n",
    "#     extra_labels=['Predicate', 'Label']\n",
    "# )\n",
    "\n",
    "# rel_result = RelationshipModel(\n",
    "#     source_node='Subject',\n",
    "#     target_node='Object',\n",
    "#     # rel_label=('column_name_label', 'predicate'),\n",
    "#     rel_label=('hard_coded_label', 'Predicate'),\n",
    "#     source_id=('subject', 'name'),\n",
    "#     target_id=('object', 'name'),\n",
    "#     # extra_labels=['Predicate', 'Result']\n",
    "# )\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.write_transaction(create_relationships, train_df_copy, [rel_train_knowledge2subject, rel_train_subject2object])\n",
    "    # session.write_transaction(create_relationships, label_df_filtered, [rel_label])\n",
    "    # session.write_transaction(create_relationships, result_df_filtered, [rel_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
